{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_A2_Q1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavi289/DL-GANs/blob/master/DL_Assign_02_Q1_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "N3EEKNLkNZdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install -q pyyaml\n",
        "!pip install gdown==3.6.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4dv-jKOEaNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import imageio\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import os \n",
        "import PIL\n",
        "import tensorflow.keras.layers as layers\n",
        "import time\n",
        "from IPython import display\n",
        "from tensorflow.python.client import device_lib\n",
        "from PIL import Image\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKSzS4rkRrk3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Load Dataset\n",
        "'''\n",
        "dataset_path = 'drive/My Drive/Semester 6/DL/Assignment 2/faces94/'\n",
        "flag = 0\n",
        "X = []\n",
        "for root, directories, files in os.walk(dataset_path):\n",
        "    \n",
        "  for file in files:\n",
        "    try:\n",
        "        file_path = root + '/' + file\n",
        "        extension_list = ['jpg', 'jpeg', 'png', 'svg']\n",
        "        if (file_path.split('.')[-1] in extension_list):\n",
        "          X.append(file_path)\n",
        "    except Exception as e:\n",
        "        print (e)   \n",
        "        pass\n",
        "\n",
        "print(\"no. of images = {}\".format(len(X)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6i14hg-BmZd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image( infilename ) :\n",
        "    img = PIL.Image.open( infilename )\n",
        "    img = img.resize((64,64))\n",
        "    img.load()\n",
        "    data = np.asarray( img, dtype=\"int32\" )\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7auNwzxVBGzI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(load_image(X[3000]), interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZWjNJ9GyBnmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test = load_image(dataset_path + \"male/gjnorm/gjnorm.6.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMyfM_u_BqaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Test Shape = {}\".format(str(test.shape)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BqkhCKx1Bs2g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(test, interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lIwaw4E_oVY",
        "colab_type": "code",
        "outputId": "dcae3eb8-7472-4f79-8139-300e8777606c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Making Minibatches\n",
        "'''\n",
        "BUFFER_SIZE = 2944\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "print(\"Number Of Batches = {}\".format(BUFFER_SIZE//BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Batches = 92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X1Uzh6sRP7Pe",
        "colab_type": "code",
        "outputId": "d2c8d217-83a2-41d2-dc1e-41f05c4640d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = np.array(X)\n",
        "np.random.shuffle(train_data)\n",
        "\n",
        "train_data = np.split(train_data[:BUFFER_SIZE], BUFFER_SIZE//BATCH_SIZE)\n",
        "\n",
        "print(\"Number of Bactches = {}\".format(len(train_data)))\n",
        "print(\"Batch Size = {}\".format(len(train_data[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Bactches = 92\n",
            "Batch Size = 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tZmgB62M__ty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "  \"\"\"\n",
        "    Implements the forward propagation for the model:\n",
        "      SEQUENTIAL -> DENSE -> NORM -> RELU -> CONV2D -> NORM -> RELU -> CONV2D -> NORM -> RELU -> CONV2D -> NORM -> RELU -> CONV2D\n",
        "    \n",
        "    Arguments:\n",
        "      None\n",
        "\n",
        "    Returns:\n",
        "      Generator Model\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  model.add(layers.Dense(4*4*1024, use_bias = False, input_shape = (100,)))\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "  \n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Reshape(( 4, 4, 1024)))\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(512, (5, 5), strides = (2,2), padding = \"same\", use_bias = False))\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "  \n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(256, (5,5), strides = (2,2), padding = \"same\", use_bias = False))\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "  \n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(128, (5,5), strides = (2,2), padding = \"same\", use_bias = False))\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "  \n",
        "  model.add(layers.LeakyReLU())\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(3, (5,5), strides = (2,2), padding = \"same\", use_bias = False, activation = \"tanh\"))\n",
        "  \n",
        "  print(\"Model Shape = {}\".format(model.output_shape))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvvA6EqREHS0",
        "colab_type": "code",
        "outputId": "2f668361-150d-419b-d515-a1204cdd83a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1,100])\n",
        "generated_image = generator(noise, training = False)\n",
        "\n",
        "print(generated_image.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Shape = (None, 64, 64, 3)\n",
            "(1, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-vpfgcDYESOB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    \"\"\"\n",
        "      Implements the forward propagation for the model:\n",
        "        SEQUENTIAL -> CONV2D -> RELU -> DROPOUT -> CONV2D -> RELU -> DROPOUT -> FLATTEN -> DENSE\n",
        "\n",
        "      Arguments:\n",
        "        None\n",
        "\n",
        "      Returns:\n",
        "        Discriminator Model\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[64, 64, 3]))\n",
        "    \n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    model.add(layers.Dropout(0.3))\n",
        "      \n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    \n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    model.add(layers.Dropout(0.3))\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    model.add(layers.Dense(1))\n",
        "     \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMDWUPwbEUuq",
        "colab_type": "code",
        "outputId": "408be431-0828-46ce-db3d-dc5382c32739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print(decision)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-4.633789e-05]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HKXgUWW3EYp-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DvvYLvIUFgmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  \"\"\"\n",
        "    Return Discriminator Loss\n",
        "    \n",
        "    Arguments:\n",
        "      real_output - Real Output\n",
        "      fake_output - Fake Output\n",
        "\n",
        "    Returns:\n",
        "      Discriminator Loss\n",
        "  \"\"\"\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  \n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZwSHLGpYFqm2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  \"\"\"\n",
        "    Return Generator Loss\n",
        "    \n",
        "    Arguments:\n",
        "      fake_output - Fake Output\n",
        "\n",
        "    Returns:\n",
        "      Generator Loss\n",
        "  \"\"\"\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7Xgh-SyFsv4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xXOTPYwFxBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Checkpoint directory\n",
        "\"\"\"\n",
        "checkpoint_dir = \"./training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer, discriminator_optimizer = discriminator_optimizer, generator = generator, discriminator = discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yumu1hVOGBa5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Saving Generator Weights\n",
        "\"\"\"\n",
        "generator.save_weights('./training_checkpoints/md')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nRFtoLcZGJIN",
        "colab_type": "code",
        "outputId": "290498c3-bba5-44da-b353-aa6dbdaacb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "generator1  = make_generator_model()\n",
        "generator1.load_weights('./training_checkpoints/md')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Shape = (None, 64, 64, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6608701940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "metadata": {
        "id": "4YK9Q-SXGLHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([1,100])\n",
        "generated_image = generator1(noise, training = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOUuJhwaGOsb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 64\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHbUQd6TNYNX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image( infilename ) :\n",
        "    img = PIL.Image.open( infilename )\n",
        "    img = img.resize((64,64))\n",
        "    img.load()\n",
        "    data = np.asarray( img, dtype=\"int32\" )\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7y5qnY7GTnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_step(images):\n",
        "    \"\"\"\n",
        "      The training loop begins with generator receiving a random seed as input. \n",
        "      That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). \n",
        "      The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator.\n",
        "      \n",
        "      Args:\n",
        "        Images\n",
        "      \n",
        "      Output:\n",
        "        Generator Loss, Discriminator Loss\n",
        "    \"\"\"\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    \n",
        "    new_images = []\n",
        "    i = 0 \n",
        "    for file_name in images:\n",
        "        i+=1\n",
        "        new_pic = load_image(file_name)\n",
        "        new_images.append(new_pic)\n",
        "    \n",
        "    images = np.array(new_images)\n",
        "    images = images.reshape(images.shape[0], 64, 64, 3).astype('float32')\n",
        "    images = (images - 127.5) / 127.5\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n",
        "    images = None\n",
        "    \n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DSnmgIL7RMsM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_loss_epoch = []\n",
        "discriminator_loss_epoch = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4PkCQpKGcab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):  \n",
        "  \"\"\"\n",
        "    Training of Model\n",
        "  \"\"\"\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    batch_no = 1\n",
        "    for image_batch in dataset:\n",
        "      batch_no += 1\n",
        "      g_loss, d_loss = train_step(image_batch)\n",
        "      \n",
        "    generator_loss_epoch.append(g_loss)\n",
        "    discriminator_loss_epoch.append(d_loss)\n",
        "    \n",
        "    print(\"Epoch = {}\".format(epoch+1))\n",
        "    print(\"\\tGenerator Loss = {}\".format(g_loss))\n",
        "    print(\"\\tDiscriminator Loss = {}\".format(d_loss))\n",
        "\n",
        "    generate_and_save_images(generator, epoch + 1, seed)\n",
        "    \n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "  generate_and_save_images(generator, epochs, seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cf_GNVMdGh7_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  result = predictions[0]\n",
        "  plt.imshow(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5BG_aSVw98q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  \n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(8, 8, i+1)\n",
        "      plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W40kNYxqG4Nn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(train_data, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IR11Rdxihqo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_and_save_images(generator, 50, seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fysUhULwQ_4P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_loss_epoch[0]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}